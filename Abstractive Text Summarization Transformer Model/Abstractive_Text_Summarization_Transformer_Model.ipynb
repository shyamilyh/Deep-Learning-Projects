{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#**Abstractive Text Summarization Transformer Model**"
      ],
      "metadata": {
        "id": "YTM3yBUUX41t"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5faee687"
      },
      "source": [
        "## Project Objective\n",
        "\n",
        "The objective of this project is to build an abstractive text summarization model using a Transformer architecture. Abstractive summarization aims to generate a concise and fluent summary that may include words or phrases not present in the original text, while capturing the most important information. We will use a prtrained model for this task."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Install Modules"
      ],
      "metadata": {
        "id": "fcpxJXqJ4GSN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers==2.8.0\n",
        "!pip install torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MRU8tdu64p04",
        "outputId": "5dfcce26-42c6-4682-af86-6153f9dc2e5f"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers==2.8.0\n",
            "  Using cached transformers-2.8.0-py3-none-any.whl.metadata (43 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from transformers==2.8.0) (2.0.2)\n",
            "Collecting tokenizers==0.5.2 (from transformers==2.8.0)\n",
            "  Using cached tokenizers-0.5.2.tar.gz (64 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting boto3 (from transformers==2.8.0)\n",
            "  Using cached boto3-1.40.64-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers==2.8.0) (3.20.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers==2.8.0) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers==2.8.0) (4.67.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers==2.8.0) (2024.11.6)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.12/dist-packages (from transformers==2.8.0) (0.2.1)\n",
            "Collecting sacremoses (from transformers==2.8.0)\n",
            "  Using cached sacremoses-0.1.1-py3-none-any.whl.metadata (8.3 kB)\n",
            "Collecting botocore<1.41.0,>=1.40.64 (from boto3->transformers==2.8.0)\n",
            "  Using cached botocore-1.40.64-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting jmespath<2.0.0,>=0.7.1 (from boto3->transformers==2.8.0)\n",
            "  Using cached jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting s3transfer<0.15.0,>=0.14.0 (from boto3->transformers==2.8.0)\n",
            "  Using cached s3transfer-0.14.0-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==2.8.0) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==2.8.0) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==2.8.0) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==2.8.0) (2025.10.5)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from sacremoses->transformers==2.8.0) (8.3.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from sacremoses->transformers==2.8.0) (1.5.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.12/dist-packages (from botocore<1.41.0,>=1.40.64->boto3->transformers==2.8.0) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.41.0,>=1.40.64->boto3->transformers==2.8.0) (1.17.0)\n",
            "Using cached transformers-2.8.0-py3-none-any.whl (563 kB)\n",
            "Using cached boto3-1.40.64-py3-none-any.whl (139 kB)\n",
            "Using cached sacremoses-0.1.1-py3-none-any.whl (897 kB)\n",
            "Using cached botocore-1.40.64-py3-none-any.whl (14.1 MB)\n",
            "Using cached jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Using cached s3transfer-0.14.0-py3-none-any.whl (85 kB)\n",
            "Building wheels for collected packages: tokenizers\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mBuilding wheel for tokenizers \u001b[0m\u001b[1;32m(\u001b[0m\u001b[32mpyproject.toml\u001b[0m\u001b[1;32m)\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Building wheel for tokenizers (pyproject.toml) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[31m  ERROR: Failed building wheel for tokenizers\u001b[0m\u001b[31m\n",
            "\u001b[0mFailed to build tokenizers\n",
            "\u001b[31mERROR: ERROR: Failed to build installable wheels for some pyproject.toml based projects (tokenizers)\u001b[0m\u001b[31m\n",
            "\u001b[0mRequirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Import Libraries"
      ],
      "metadata": {
        "id": "5qtK2hME42c1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration"
      ],
      "metadata": {
        "id": "94xaIXk3443f"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "38f5c2de"
      },
      "source": [
        "## Model Implementation\n",
        "Initialize the T5 model and tokenizer."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#initialize the pretrained model\n",
        "model = T5ForConditionalGeneration.from_pretrained('t5-small')\n",
        "tokenizer = T5Tokenizer.from_pretrained('t5-small')\n",
        "device = torch.device('cpu')"
      ],
      "metadata": {
        "id": "MmMGShWj5co_"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#input text\n",
        "\n",
        "text = \"\"\"\n",
        "Artificial Intelligence (AI) is rapidly transforming how the world works, creating a new era of innovation across industries.\n",
        "With breakthroughs in generative AI, machine learning, and natural language processing, machines are now capable of analyzing, learning, and even creating like humans.\n",
        "Businesses are using AI to automate processes, enhance customer experiences, and make data-driven decisions faster than ever before.\n",
        "This technological shift is leading to massive growth opportunities, helping companies boost efficiency and gain a competitive edge.\n",
        "However, AI’s rise also brings a shift in the job market — while repetitive tasks are being automated, new roles in data science, AI ethics, and prompt engineering are emerging.\n",
        "The future workforce will need strong analytical and creative skills to work alongside intelligent systems.\n",
        "For employees and organizations alike, upskilling in AI technologies will become essential.\n",
        "In the coming years, AI will become more ethical, personalized, and embedded in daily life — from healthcare and education to finance and entertainment. Rather than replacing humans, AI will empower them to focus on strategy, empathy, and innovation.\n",
        "The future belongs to those who can combine human intelligence with machine intelligence to drive progress.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "pi9FGM5i6Hr_"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "31306405"
      },
      "source": [
        "## Data Preprocessing\n",
        "\n",
        "Data preprocessing involves preparing the text data for input into the Transformer model. This includes tokenization, handling special characters, and formatting the data as required by the model."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#preprocess the input text\n",
        "preprocessed_text = text.strip().replace('\\n', '')\n",
        "t5_input_text = 'summarize: ' + preprocessed_text"
      ],
      "metadata": {
        "id": "LV8PaWTM63nh"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t5_input_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "iAOdcDoH75vv",
        "outputId": "a8cfce02-a283-4928-e4c5-6eb6d309be56"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'summarize: Artificial Intelligence (AI) is rapidly transforming how the world works, creating a new era of innovation across industries. With breakthroughs in generative AI, machine learning, and natural language processing, machines are now capable of analyzing, learning, and even creating like humans. Businesses are using AI to automate processes, enhance customer experiences, and make data-driven decisions faster than ever before.This technological shift is leading to massive growth opportunities, helping companies boost efficiency and gain a competitive edge.However, AI’s rise also brings a shift in the job market — while repetitive tasks are being automated, new roles in data science, AI ethics, and prompt engineering are emerging. The future workforce will need strong analytical and creative skills to work alongside intelligent systems.For employees and organizations alike, upskilling in AI technologies will become essential.In the coming years, AI will become more ethical, personalized, and embedded in daily life — from healthcare and education to finance and entertainment. Rather than replacing humans, AI will empower them to focus on strategy, empathy, and innovation. The future belongs to those who can combine human intelligence with machine intelligence to drive progress.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(t5_input_text.split())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C1pmoMhi7_kW",
        "outputId": "6d759125-eb56-457c-94ad-59e3e643088e"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "186"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_text = tokenizer.encode(t5_input_text, return_tensors = 'pt', max_length = 512, truncation= True).to(device)\n"
      ],
      "metadata": {
        "id": "Bad7VMGU8JbV"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Summary"
      ],
      "metadata": {
        "id": "vC0qHP_I8mD4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "summary_ids = model.generate(tokenized_text, min_length = 30, max_length = 120)\n",
        "summary = tokenizer.decode(summary_ids[0], skip_special_tokens= True)"
      ],
      "metadata": {
        "id": "RBYuSbFU8new"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "id": "jB2l8ION9I-Y",
        "outputId": "b834fe68-7547-4525-b206-8da56ecf0cda"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'AI is rapidly transforming how the world works, creating a new era of innovation across industries. businesses are using AI to automate processes, enhance customer experiences, and make data-driven decisions faster than ever before. this technological shift is leading to massive growth opportunities, helping companies boost efficiency and gain a competitive edge.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2c4e7ee4"
      },
      "source": [
        "## Conclusion\n",
        "\n",
        "In this project, we aimed to build an abstractive text summarization model using a Transformer architecture. We chose the T5 model and demonstrated the initial steps of tokenization and generating a summary using the pre-trained model."
      ]
    }
  ]
}